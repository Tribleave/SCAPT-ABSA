mode: aspect_finetune
model: BERT

device: 0
data_path: data/laptops
model_path: results/laptops
train_file: Laptops_Train_v2_Implicit_Labeled_preprocess_finetune.pkl
test_file: Laptops_Test_Gold_Implicit_Labeled_preprocess_finetune.pkl
num_workers_per_loader: 16

seed: 42
batch_size: 32
dropout: 0.1
epoch: 6
warm_up: 70
label_smooth: 0.01

optimizer: adamw
learning_rate: 0.00005
weight_decay: 0.015
grad_norm: 5.0
